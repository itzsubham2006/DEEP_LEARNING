{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb672cc",
   "metadata": {},
   "source": [
    "### **Importing the dependecies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03aee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d19896",
   "metadata": {},
   "source": [
    "### **Removing HTML tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17b7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = '''\n",
    "<div class=\"post\">\n",
    "  <h2>Welcome to <span style=\"color:blue;\">My Blog</span></h2>\n",
    "  <p>\n",
    "    This is a <b>random</b> paragraph with <i>different</i> HTML tags.\n",
    "    You might see <a href=\"#\">links</a>, <u>underlined text</u>,\n",
    " ird tag <custom-tag>hello</custom-tag>.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45790903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_cleanp(data):\n",
    "    p = re.compile(r'<*.?>')\n",
    "    return p.sub('', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf3c410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<div class=\"post\\n  <hWelcome to <span style=\"color:blue;My Blog</spa</h\\n  \\n    This is a random</ paragraph with different</ HTML tags.\\n    You might see <a href=\"#links</, underlined text</,\\n ird tag <custom-tahello</custom-ta.\\n  </\\n</di\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_cleanp(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7bf53f",
   "metadata": {},
   "source": [
    "### **Unicode Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e901fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_Text = '''If you want, next we can:\n",
    "\n",
    "ðŸ”¥ apply greedy vs non-greedy regex on this\n",
    "\n",
    "ðŸ§ª run your remove() function on it\n",
    "\n",
    "ðŸ§  compare regex vs BeautifulSoup output\n",
    "\n",
    "Just tell me ðŸ˜Ž'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60121eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'If you want, next we can:\\n\\n\\xf0\\x9f\\x94\\xa5 apply greedy vs non-greedy regex on this\\n\\n\\xf0\\x9f\\xa7\\xaa run your remove() function on it\\n\\n\\xf0\\x9f\\xa7\\xa0 compare regex vs BeautifulSoup output\\n\\nJust tell me \\xf0\\x9f\\x98\\x8e'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_Text.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637f9bb",
   "metadata": {},
   "source": [
    "### **SPELLING CORRECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81513f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "text = 'Hi this is just a random person writinggg with the keyboarrd p to write 100 wpm tyyping speed, lets see he can do it or no, currently he is doing speling coreetion lets see he can do it or not.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1fc7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I this is just a random person writing with the keyboard p to write 100 wm trying speed, lets see he can do it or no, currently he is doing spelling creation lets see he can do it or not.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblb = TextBlob(text)\n",
    "\n",
    "textblb.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099faec8",
   "metadata": {},
   "source": [
    "### **Tokenizing the sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db66a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ea98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentene = 'hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly , i am learning NLP from CampusX, and i think he is. hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly , i am learning NLP from CampusX, and i think he is.hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly , i am learning NLP from CampusX, and i think he is. hiiiiii this is a .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8643a067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly , i am learning NLP from CampusX, and i think he is.',\n",
       " 'hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly , i am learning NLP from CampusX, and i think he is.hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly , i am learning NLP from CampusX, and i think he is.',\n",
       " 'hiiiiii this is a .']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = sent_tokenize(sentene)\n",
    "sents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef17cce",
   "metadata": {},
   "source": [
    "#### **Word Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4d6d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hiiiiii', 'this', 'is', 'a', 'introvert', 'typing', 'some', 'random', 'shits', 'i', 'really', 'dont', 'know', 'what', 'to', 'type', 'so', 'that', 'i', 'am', 'typign', 'randomly', ',', 'i', 'am', 'learning', 'NLP', 'from', 'CampusX', ',', 'and', 'i', 'think', 'he', 'is', '.']\n",
      "['hiiiiii', 'this', 'is', 'a', 'introvert', 'typing', 'some', 'random', 'shits', 'i', 'really', 'dont', 'know', 'what', 'to', 'type', 'so', 'that', 'i', 'am', 'typign', 'randomly', ',', 'i', 'am', 'learning', 'NLP', 'from', 'CampusX', ',', 'and', 'i', 'think', 'he', 'is.hiiiiii', 'this', 'is', 'a', 'introvert', 'typing', 'some', 'random', 'shits', 'i', 'really', 'dont', 'know', 'what', 'to', 'type', 'so', 'that', 'i', 'am', 'typign', 'randomly', ',', 'i', 'am', 'learning', 'NLP', 'from', 'CampusX', ',', 'and', 'i', 'think', 'he', 'is', '.']\n",
      "['hiiiiii', 'this', 'is', 'a', '.']\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650eb996",
   "metadata": {},
   "outputs": [],
   "source": [
    "docss = '<p>hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly</p> hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly<p></p>hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly <p></p> <p>hiiiiii this is a introvert typing some random shits i really dont know what to type so that i am typign randomly</p>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39662f2e",
   "metadata": {},
   "source": [
    "### **Lowercasing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6728429",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '''\n",
    "\n",
    "Lorem ipsum dolor, sit amet consectetur adipisicing elit. Maxime, iste cum? Repudiandae aliquam vero tempora nisi eum culpa! Vero dolore necessitatibus ipsa, blanditiis dolor tempore atque recusitae quam dolorem saepe repellat doloribus blanditiis, eos temporibus. Labore eum dicta totam cum ut eius obcaecati natus! Lorem ipsum dolor, sit amet consectetur adipisicing elit. Qui debitis aliquid, magnam dolorem, fugiat numquam, mollitia porro commodi eaque omnis voluptates iste? Eum nihil a amet consectetur cum? Voluptate, esse!\n",
    "    Ulltio repellendus laudantium obcaecati dolorem quisquam error libero officiis provident magnam. Recusandae est ducimus quae molestiae nemo quaerat ratione aliquam! Dolores culpa ut unde repellendus reiciendis pariatur soluta.\n",
    "   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7929447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "lorem ipsum dolor, sit amet consectetur adipisicing elit. maxime, iste cum? repudiandae aliquam vero tempora nisi eum culpa! vero dolore necessitatibus ipsa, blanditiis dolor tempore atque recusitae quam dolorem saepe repellat doloribus blanditiis, eos temporibus. labore eum dicta totam cum ut eius obcaecati natus! lorem ipsum dolor, sit amet consectetur adipisicing elit. qui debitis aliquid, magnam dolorem, fugiat numquam, mollitia porro commodi eaque omnis voluptates iste? eum nihil a amet consectetur cum? voluptate, esse!\n",
      "    ulltio repellendus laudantium obcaecati dolorem quisquam error libero officiis provident magnam. recusandae est ducimus quae molestiae nemo quaerat ratione aliquam! dolores culpa ut unde repellendus reiciendis pariatur soluta.\n",
      "   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16356ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"/mnt/c/Users/Subham Pathak/Desktop/AI/DEEP_LEARNING/notebooks/NLP/datasets/IMDB Dataset.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da828ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phil the alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.<br /><br />at first it was very odd and pretty funny but as the movie progressed i didn\\'t find the jokes or oddness funny anymore.<br /><br />its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually i just lost interest.<br /><br />i imagine this film would appeal to a stoner who is currently partaking.<br /><br />for something similar but better try \"brother from another planet\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][10].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4161055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if u want to lower all the data inside csv files\n",
    "\n",
    "data['review'] = data['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d5fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '''\n",
    "<p> Hiii this is Subham Pathak typinginto the keyboard , he really dont know anything...</p?\n",
    "<p> iii thihits into the keyboard , he really dont know anything...</p>\n",
    "<p> Hii this ime random shits into the keyboard , he really dont know anything...</p>\n",
    "<p> Hiii this is Subham Pathak typing some random srd , he really dont know anything...</p>\n",
    "<p> Hii tPathakme random shits into the, he really dont know anything...</p>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "816a4973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Hiii this is Subham Pathak typinginto the keyboard , he really dont know anything...</p?\\n iii thihits into the keyboard , he really dont know anything...</\\n Hii this ime random shits into the keyboard , he really dont know anything...</\\n Hiii this is Subham Pathak typing some random srd , he really dont know anything...</\\n Hii tPathakme random shits into the, he really dont know anything...</\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def process(datas):\n",
    "    p = re.compile(r'<*.?>')\n",
    "    return p.sub('', datas)\n",
    "\n",
    "\n",
    "process(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380c8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5319f95",
   "metadata": {},
   "source": [
    "### **Remove URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aaf452d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhiiiiii this is my link  of github and my linkedin acc is \\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string\n",
    "text = '''\n",
    "hiiiiii this is my link https://github.com/itzsubham2006?tab=overview&from=2026-01-01&to=2026-01-18 of github and my linkedin acc is https://www.linkedin.com/feed/.\n",
    "\n",
    "'''\n",
    "\n",
    "def remove_url(text):\n",
    "    t = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return t.sub(r'', text)\n",
    "\n",
    "\n",
    "remove_url(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999b5dd",
   "metadata": {},
   "source": [
    "### **Remove Punctuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fea19e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, time\n",
    "exclude = string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e40877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char, '')\n",
    "        \n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68734455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi this is subham pathakl typing some andom  shits'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct(\"Hi, this is subham! pathakl'' typing. some andom $ shits`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9461c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.58306884765625e-05\n"
     ]
    }
   ],
   "source": [
    "def make_translate(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "make_translate(\"Hi, this is subham! pathakl'' typing. some andom $ shits`\")\n",
    "time1 = time.time() - start\n",
    "\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc201e89",
   "metadata": {},
   "source": [
    "### **REVISION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "455d9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "<p>Discover the <strong>latest trends</strong> in web development! ðŸš€<br>\n",
    "Visit our <a href=\"https://www.example.com/news\">official blog</a> for updates.<br>\n",
    "Need help? Check out the <em>FAQ section</em> at <a href=\"https://support.example.com\">support.example.com</a>.<br>\n",
    "Stay inspired with daily <i>motivational quotes</i> from <a href=\"https://quotes.example.org/random\">quotes.example.org</a>.</p>\n",
    "\n",
    "<h3>Random Tip:</h3>\n",
    "<ul>\n",
    "  <li>Use <code>lorem5</code> in VS Code to generate <em>lorem ipsum</em> text instantly.</li>\n",
    "  <li>Test links with <a href=\"https://validator.w3.org/\">W3C Validator</a>.</li>\n",
    "</ul>   \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "872741b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDiscover the <stronlatest trends</stron in web development! ðŸš€<b\\nVisit our <a href=\"https://www.example.com/newsofficial blog</ for updates.<b\\nNeed help? Check out the <eFAQ section</e at <a href=\"https://support.example.comsupport.example.com</.<b\\nStay inspired with daily motivational quotes</ from <a href=\"https://quotes.example.org/randomquotes.example.org</.</\\n\\n<hRandom Tip:</h\\n<u\\n  <lUse <codlorem5</cod in VS Code to generate <elorem ipsum</e text instantly.</l\\n  <lTest links with <a href=\"https://validator.w3.org/W3C Validator</.</l\\n</u   \\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the html tags\n",
    "import re\n",
    "def rmeove_html(data):\n",
    "    p = re.compile(r'<*.?>')\n",
    "    return p.sub(r'', data)\n",
    "\n",
    "rmeove_html(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2652c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the emojis and all the these stuffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e39d1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"\n",
       "<p>Discover the <strong>latest tends</strong> in web development! ðŸš€<br>\n",
       "Visit our <a he=\"http://www.example.com/news\">official blow</a> for updated.<br>\n",
       "Need help? Check out the <em>FAQ section</em> at <a he=\"http://support.example.com\">support.example.com</a>.<br>\n",
       "Stay inspired with daily <i>motivation quotes</i> from <a he=\"http://quotes.example.org/random\">quotes.example.org</a>.</p>\n",
       "\n",
       "<he>Random Lip:</he>\n",
       "<up>\n",
       "  <li>Use <code>lore</code> in of Rode to generate <em>lore issue</em> text instantly.</li>\n",
       "  <li>West links with <a he=\"http://validator.we.org/\">W3C Validator</a>.</li>\n",
       "</up>   \n",
       "\n",
       "\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spelling corerction\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "test = TextBlob(text)\n",
    "\n",
    "test.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85e7f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n<p>Discover the <strong>latest trends</strong> in web development!', 'ðŸš€<br>\\nVisit our <a href=\"https://www.example.com/news\">official blog</a> for updates.<br>\\nNeed help?', 'Check out the <em>FAQ section</em> at <a href=\"https://support.example.com\">support.example.com</a>.<br>\\nStay inspired with daily <i>motivational quotes</i> from <a href=\"https://quotes.example.org/random\">quotes.example.org</a>.</p>\\n\\n<h3>Random Tip:</h3>\\n<ul>\\n  <li>Use <code>lorem5</code> in VS Code to generate <em>lorem ipsum</em> text instantly.</li>\\n  <li>Test links with <a href=\"https://validator.w3.org/\">W3C Validator</a>.</li>\\n</ul>']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "tokenize_sentence = sent_tokenize(text)\n",
    "print(tokenize_sentence)\n",
    "print(len(tokenize_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a82ebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', 'p', '>', 'Discover', 'the', '<', 'strong', '>', 'latest', 'trends', '<', '/strong', '>', 'in', 'web', 'development', '!']\n",
      "['ðŸš€', '<', 'br', '>', 'Visit', 'our', '<', 'a', 'href=', \"''\", 'https', ':', '//www.example.com/news', \"''\", '>', 'official', 'blog', '<', '/a', '>', 'for', 'updates.', '<', 'br', '>', 'Need', 'help', '?']\n",
      "['Check', 'out', 'the', '<', 'em', '>', 'FAQ', 'section', '<', '/em', '>', 'at', '<', 'a', 'href=', \"''\", 'https', ':', '//support.example.com', \"''\", '>', 'support.example.com', '<', '/a', '>', '.', '<', 'br', '>', 'Stay', 'inspired', 'with', 'daily', '<', 'i', '>', 'motivational', 'quotes', '<', '/i', '>', 'from', '<', 'a', 'href=', \"''\", 'https', ':', '//quotes.example.org/random', \"''\", '>', 'quotes.example.org', '<', '/a', '>', '.', '<', '/p', '>', '<', 'h3', '>', 'Random', 'Tip', ':', '<', '/h3', '>', '<', 'ul', '>', '<', 'li', '>', 'Use', '<', 'code', '>', 'lorem5', '<', '/code', '>', 'in', 'VS', 'Code', 'to', 'generate', '<', 'em', '>', 'lorem', 'ipsum', '<', '/em', '>', 'text', 'instantly.', '<', '/li', '>', '<', 'li', '>', 'Test', 'links', 'with', '<', 'a', 'href=', \"''\", 'https', ':', '//validator.w3.org/', \"''\", '>', 'W3C', 'Validator', '<', '/a', '>', '.', '<', '/li', '>', '<', '/ul', '>']\n"
     ]
    }
   ],
   "source": [
    "for word in tokenize_sentence:\n",
    "    word_tokenize(word)\n",
    "    print(word_tokenize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "619a8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "hehe = string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "636e0de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npDiscover the stronglatest trendsstrong in web development ðŸš€br\\nVisit our a hrefhttpswwwexamplecomnewsofficial bloga for updatesbr\\nNeed help Check out the emFAQ sectionem at a hrefhttpssupportexamplecomsupportexamplecomabr\\nStay inspired with daily imotivational quotesi from a hrefhttpsquotesexampleorgrandomquotesexampleorgap\\n\\nh3Random Tiph3\\nul\\n  liUse codelorem5code in VS Code to generate emlorem ipsumem text instantlyli\\n  liTest links with a hrefhttpsvalidatorw3orgW3C Validatorali\\nul   \\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(data):\n",
    "    return data.translate(str.maketrans('','', hehe))\n",
    "\n",
    "\n",
    "remove_punctuation(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed13dd",
   "metadata": {},
   "source": [
    "### **Chat words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36cde6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    'lol' : 'laugh out loud',\n",
    "    'u' : 'you',\n",
    "    'wyd' : 'what are you doing',\n",
    "    'gd nyt' : 'good night',\n",
    "    'ilysm' : 'i love you so much',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db08f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_text(data):\n",
    "    new_text = []\n",
    "    for s in data.split():\n",
    "        if s in sample:\n",
    "            new_text.append(sample[s])\n",
    "        else:\n",
    "            new_text.append(s)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df2a60c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi today laugh out loud happen'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text('Hi today lol happen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662c051",
   "metadata": {},
   "source": [
    "### **Removing stop_words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8de30043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efe3ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b182d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = []\n",
    "\n",
    "def rm_stopwords(text):\n",
    "    for i in text.split():\n",
    "        if i in stopwords.words('english'):\n",
    "            new_words.append('')\n",
    "        else:\n",
    "            new_words.append(i)\n",
    "    x = new_words[:]\n",
    "    new_words.clear()\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e98ee82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello     right now,  name    subham pathak'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_stopwords('hello what are you doing right now, the name of me is subham pathak')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf95f0f",
   "metadata": {},
   "source": [
    "### **Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a862745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebf15186",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stemming(text):\n",
    "    return ' '.join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72f5e0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he is walk and i am run , do u know what is the differ between these two lines, if ye answer it'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming('he is walking and i am running , do u know what is the difference between these two lines, if yes answer it')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71934a8f",
   "metadata": {},
   "source": [
    "### **FEATURE EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fc84eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fc749de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi how are you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi my name is subham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am learning NLP from campusX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am learning NLP now</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am a man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  output\n",
       "0                  hi how are you       1\n",
       "1            hi my name is subham       1\n",
       "2  I am learning NLP from campusX       1\n",
       "3           I am learning NLP now       0\n",
       "4                      I am a man       0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text':['hi how are you', 'hi my name is subham', 'I am learning NLP from campusX', 'I am learning NLP now', 'I am a man'], 'output':[1,1,1,0,0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f352072",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "bow = cv.fit_transform(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67c38eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': 4, 'how': 5, 'are': 1, 'you': 14, 'my': 9, 'name': 10, 'is': 6, 'subham': 13, 'am': 0, 'learning': 7, 'nlp': 11, 'from': 3, 'campusx': 2, 'now': 12, 'man': 8}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d4014c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 1 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1249a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72f424e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_voc = (max(cv.vocabulary_.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd8c85e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 1 0 1 0 0 1 1 0 0 1 0]\n",
      "[1 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    print(bow[i].toarray()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3f64a",
   "metadata": {},
   "source": [
    "### **Bag of n-grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da396fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal bag-of-words = n=(1,1)\n",
    "# bi-grams = n=(2,2)\n",
    "# tri-grams = n = (3,3)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range = (2,2)) #       bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d54401a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi how are you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi my name is subham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am learning NLP from campusX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am learning NLP now</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am a man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  output\n",
       "0                  hi how are you       1\n",
       "1            hi my name is subham       1\n",
       "2  I am learning NLP from campusX       1\n",
       "3           I am learning NLP now       0\n",
       "4                      I am a man       0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb72953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 15 stored elements and shape (5, 13)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "132271f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi how': 4,\n",
       " 'how are': 6,\n",
       " 'are you': 2,\n",
       " 'hi my': 5,\n",
       " 'my name': 9,\n",
       " 'name is': 10,\n",
       " 'is subham': 7,\n",
       " 'am learning': 0,\n",
       " 'learning nlp': 8,\n",
       " 'nlp from': 11,\n",
       " 'from campusx': 3,\n",
       " 'nlp now': 12,\n",
       " 'am man': 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece62876",
   "metadata": {},
   "source": [
    "### **TF(Term Frequency)-IDF(Inverse Document frequency)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dd28637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi how are you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi my name is subham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am learning NLP from campusX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am learning NLP now</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am a man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  output\n",
       "0                  hi how are you       1\n",
       "1            hi my name is subham       1\n",
       "2  I am learning NLP from campusX       1\n",
       "3           I am learning NLP now       0\n",
       "4                      I am a man       0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f3f28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f6e75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 15)\n"
     ]
    }
   ],
   "source": [
    "tfid = TfidfVectorizer()\n",
    "\n",
    "vector = tfid.fit_transform(df['text']).toarray()\n",
    "\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1acd9340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40546511 2.09861229 2.09861229 2.09861229 1.69314718 2.09861229\n",
      " 2.09861229 1.69314718 2.09861229 2.09861229 2.09861229 1.69314718\n",
      " 2.09861229 2.09861229 2.09861229]\n",
      "\n",
      "\n",
      "['am' 'are' 'campusx' 'from' 'hi' 'how' 'is' 'learning' 'man' 'my' 'name'\n",
      " 'nlp' 'now' 'subham' 'you']\n"
     ]
    }
   ],
   "source": [
    "print(tfid.idf_)\n",
    "print('\\n')\n",
    "print(tfid.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d96784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
